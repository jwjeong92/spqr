{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "H_dict = torch.load('collected_H/H_opt-6.7b_pajama_seed0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from spqr.evalutils import evaluate_perplexity\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "model_path = '/raid/LLM/opt-6.7b/'\n",
    "device = 'cuda:3'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.half)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spqr.quant_groups import Quantizer, quantize, dequantize, quantize_dequantize\n",
    "from spqr.spqr_engine import calculate_bit_error_injection_mask_quantized\n",
    "import time\n",
    "\n",
    "linear_list = [\n",
    "    'self_attn.k_proj',\n",
    "    'self_attn.q_proj',\n",
    "    'self_attn.v_proj',\n",
    "    'self_attn.out_proj',\n",
    "    'fc1',\n",
    "    'fc2',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "qweight_dict = {}\n",
    "row_perm_dict = {}\n",
    "scale_dict = {}\n",
    "zero_dict = {}\n",
    "for i in range(len(layers)):\n",
    "    qweight_dict[i] = {}\n",
    "    row_perm_dict[i] = {}\n",
    "    scale_dict[i] = {}\n",
    "    zero_dict[i] = {}\n",
    "    layer = layers[i]\n",
    "    sublayers = {name: sublayer for name, sublayer in layer.named_modules() if name in linear_list}\n",
    "    for name, sublayer in sublayers.items():\n",
    "        tick = time.time()\n",
    "        weight = sublayer.weight.detach().clone()\n",
    "        col_perm, dead, H_inv_diag = H_dict[i][name]\n",
    "        weight = weight[:, col_perm]\n",
    "        weight[:, dead] = 0\n",
    "        weight = weight.to(device)\n",
    "        out_dim, in_dim = weight.shape\n",
    "\n",
    "        quantizer = Quantizer(weight.shape)\n",
    "        quantizer.configure(4, True, False)\n",
    "        quantizer.find_params(weight, weight=True)\n",
    "        row_perm = torch.argsort(quantizer.scale.T.squeeze(), descending=True).to(device)\n",
    "        qweight = quantize(weight, quantizer.scale, quantizer.zero, quantizer.maxq)\n",
    "        qweight = qweight[row_perm, :]\n",
    "        qweight_dict[i][name] = qweight.to(torch.int8)\n",
    "        row_perm_dict[i][name] = row_perm\n",
    "        scale_dict[i][name] = quantizer.scale\n",
    "        zero_dict[i][name] = quantizer.zero\n",
    "    \n",
    "torch.save(qweight_dict, f'ordered_quant_models/opt-6.7b-qweight.pt')\n",
    "torch.save(row_perm_dict, f'ordered_quant_models/opt-6.7b-row-perm.pt')\n",
    "torch.save(scale_dict, f'ordered_quant_models/opt-6.7b-scale.pt')\n",
    "torch.save(zero_dict, f'ordered_quant_models/opt-6.7b-zero.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spqr.errorutils import error_injection\n",
    "\n",
    "qweight_dict = torch.load(f'ordered_quant_models/opt-6.7b-qweight.pt')\n",
    "row_perm_dict = torch.load(f'ordered_quant_models/opt-6.7b-row-perm.pt')\n",
    "scale_dict = torch.load(f'ordered_quant_models/opt-6.7b-scale.pt')\n",
    "zero_dict = torch.load(f'ordered_quant_models/opt-6.7b-zero.pt')\n",
    "for i in qweight_dict:\n",
    "    for name in qweight_dict[i]:\n",
    "        qweight_dict[i][name] = qweight_dict[i][name].to(device)\n",
    "        row_perm_dict[i][name] = row_perm_dict[i][name].to(device)\n",
    "        scale_dict[i][name] = scale_dict[i][name].to(device)\n",
    "        zero_dict[i][name] = zero_dict[i][name].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for percentile in range(10, 1, -1):\n",
    "    print(f'error masking percentile: {percentile}%')\n",
    "    seed = 0\n",
    "    cp_model = deepcopy(model).to(device)\n",
    "    layers = cp_model.model.decoder.layers\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        sublayers = {name: sublayer for name, sublayer in layer.named_modules() if name in linear_list}\n",
    "        for name, sublayer in sublayers.items():\n",
    "            qweight = qweight_dict[i][name].clone()\n",
    "            row_perm = row_perm_dict[i][name]\n",
    "            col_perm, _, _ = H_dict[i][name]\n",
    "            col_perm = col_perm.to(device)\n",
    "            err_matrix = error_injection(\n",
    "                qweight, 1e-3, seed, 4, device\n",
    "            ).reshape_as(qweight)\n",
    "            err_mask_row = round(qweight.shape[0] * (percentile/100))\n",
    "            err_mask_col = round(qweight.shape[1] * (percentile/100))\n",
    "            err_matrix[:err_mask_row, :err_mask_col] = 0\n",
    "            qweight = qweight.to(torch.int32) ^ err_matrix.to(device)\n",
    "            row_invperm = torch.argsort(row_perm).to(device)\n",
    "            qweight = qweight[row_invperm, :]\n",
    "            scale = scale_dict[i][name].to(device)\n",
    "            zero = zero_dict[i][name].to(device)\n",
    "            dqweight = dequantize(qweight, scale, zero)\n",
    "\n",
    "            col_invperm = torch.argsort(col_perm).to(device)\n",
    "            dqweight = dqweight[:, col_invperm]\n",
    "            sublayer.weight.data = dqweight.to(device)\n",
    "            seed = seed + 10\n",
    "\n",
    "    if model.device == device:\n",
    "        print(evaluate_perplexity(cp_model, tokenizer))\n",
    "    else:\n",
    "        print(evaluate_perplexity(cp_model.to(device), tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spqr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
