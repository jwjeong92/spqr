{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwjeong/miniconda3/envs/spqr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/raid/LLM/opt-6.7b/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:467\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    466\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/transformers/modeling_utils.py:2611\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2608\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[1;32m   2610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 2611\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[38;5;66;03m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:817\u001b[0m, in \u001b[0;36mOPTForCausalLM.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mOPTModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;66;03m# the lm_head weight is automatically tied to the embed tokens weight\u001b[39;00m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mword_embed_proj_dim, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:749\u001b[0m, in \u001b[0;36mOPTModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: OPTConfig):\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m--> 749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m \u001b[43mOPTDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_init()\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:520\u001b[0m, in \u001b[0;36mOPTDecoder.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\u001b[43m[\u001b[49m\u001b[43mOPTDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:520\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mOPTDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/transformers/models/opt/modeling_opt.py:293\u001b[0m, in \u001b[0;36mOPTDecoderLayer.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn \u001b[38;5;241m=\u001b[39m ACT2FN[config\u001b[38;5;241m.\u001b[39mactivation_function]\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_layer_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, elementwise_affine\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_elementwise_affine\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mffn_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, bias\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39menable_bias)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, elementwise_affine\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_elementwise_affine)\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/torch/nn/modules/linear.py:101\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/torch/nn/modules/linear.py:107\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/miniconda3/envs/spqr/lib/python3.11/site-packages/torch/nn/init.py:412\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    410\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from spqr.evalutils import evaluate_perplexity\n",
    "import torch\n",
    "\n",
    "model_path = '/raid/LLM/opt-6.7b/'\n",
    "device = 'cuda:1'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.half)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_list = [\n",
    "    'self_attn.k_proj',\n",
    "    'self_attn.q_proj',\n",
    "    'self_attn.v_proj',\n",
    "    'self_attn.out_proj',\n",
    "    'fc1',\n",
    "    'fc2',\n",
    "]\n",
    "\n",
    "layers = model.model.decoder.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time - layer0 self_attn.k_proj quant. = 0.020861148834228516\n",
      "elapsed time - layer0 self_attn.v_proj quant. = 0.01961207389831543\n",
      "elapsed time - layer0 self_attn.q_proj quant. = 0.019977092742919922\n",
      "elapsed time - layer0 self_attn.out_proj quant. = 0.01851677894592285\n",
      "elapsed time - layer0 fc1 quant. = 0.12583065032958984\n",
      "elapsed time - layer0 fc2 quant. = 0.13869667053222656\n",
      "elapsed time - layer1 self_attn.k_proj quant. = 0.03807497024536133\n",
      "elapsed time - layer1 self_attn.v_proj quant. = 0.03750133514404297\n",
      "elapsed time - layer1 self_attn.q_proj quant. = 0.03751397132873535\n",
      "elapsed time - layer1 self_attn.out_proj quant. = 0.038033246994018555\n",
      "elapsed time - layer1 fc1 quant. = 0.1351490020751953\n",
      "elapsed time - layer1 fc2 quant. = 0.13621830940246582\n",
      "elapsed time - layer2 self_attn.k_proj quant. = 0.03778243064880371\n",
      "elapsed time - layer2 self_attn.v_proj quant. = 0.046547889709472656\n",
      "elapsed time - layer2 self_attn.q_proj quant. = 0.038790225982666016\n",
      "elapsed time - layer2 self_attn.out_proj quant. = 0.03833436965942383\n",
      "elapsed time - layer2 fc1 quant. = 0.13096833229064941\n",
      "elapsed time - layer2 fc2 quant. = 0.13408279418945312\n",
      "elapsed time - layer3 self_attn.k_proj quant. = 0.03687262535095215\n",
      "elapsed time - layer3 self_attn.v_proj quant. = 0.03815746307373047\n",
      "elapsed time - layer3 self_attn.q_proj quant. = 0.03934025764465332\n",
      "elapsed time - layer3 self_attn.out_proj quant. = 0.03863644599914551\n",
      "elapsed time - layer3 fc1 quant. = 0.1302039623260498\n",
      "elapsed time - layer3 fc2 quant. = 0.1270132064819336\n",
      "elapsed time - layer4 self_attn.k_proj quant. = 0.036344289779663086\n",
      "elapsed time - layer4 self_attn.v_proj quant. = 0.03680682182312012\n",
      "elapsed time - layer4 self_attn.q_proj quant. = 0.03684544563293457\n",
      "elapsed time - layer4 self_attn.out_proj quant. = 0.03508329391479492\n",
      "elapsed time - layer4 fc1 quant. = 0.10736870765686035\n",
      "elapsed time - layer4 fc2 quant. = 0.10495376586914062\n",
      "elapsed time - layer5 self_attn.k_proj quant. = 0.03137683868408203\n",
      "elapsed time - layer5 self_attn.v_proj quant. = 0.03155827522277832\n",
      "elapsed time - layer5 self_attn.q_proj quant. = 0.03147077560424805\n",
      "elapsed time - layer5 self_attn.out_proj quant. = 0.03093552589416504\n",
      "elapsed time - layer5 fc1 quant. = 0.10597658157348633\n",
      "elapsed time - layer5 fc2 quant. = 0.11017251014709473\n",
      "elapsed time - layer6 self_attn.k_proj quant. = 0.032442569732666016\n",
      "elapsed time - layer6 self_attn.v_proj quant. = 0.03432750701904297\n",
      "elapsed time - layer6 self_attn.q_proj quant. = 0.03527474403381348\n",
      "elapsed time - layer6 self_attn.out_proj quant. = 0.034670352935791016\n",
      "elapsed time - layer6 fc1 quant. = 0.12503337860107422\n",
      "elapsed time - layer6 fc2 quant. = 0.12553691864013672\n",
      "elapsed time - layer7 self_attn.k_proj quant. = 0.03766655921936035\n",
      "elapsed time - layer7 self_attn.v_proj quant. = 0.03654336929321289\n",
      "elapsed time - layer7 self_attn.q_proj quant. = 0.035408735275268555\n",
      "elapsed time - layer7 self_attn.out_proj quant. = 0.03647947311401367\n",
      "elapsed time - layer7 fc1 quant. = 0.12788939476013184\n",
      "elapsed time - layer7 fc2 quant. = 0.12318253517150879\n",
      "elapsed time - layer8 self_attn.k_proj quant. = 0.03586435317993164\n",
      "elapsed time - layer8 self_attn.v_proj quant. = 0.037368059158325195\n",
      "elapsed time - layer8 self_attn.q_proj quant. = 0.03806805610656738\n",
      "elapsed time - layer8 self_attn.out_proj quant. = 0.038895606994628906\n",
      "elapsed time - layer8 fc1 quant. = 0.1256580352783203\n",
      "elapsed time - layer8 fc2 quant. = 0.10222244262695312\n",
      "elapsed time - layer9 self_attn.k_proj quant. = 0.028850555419921875\n",
      "elapsed time - layer9 self_attn.v_proj quant. = 0.029549360275268555\n",
      "elapsed time - layer9 self_attn.q_proj quant. = 0.030036211013793945\n",
      "elapsed time - layer9 self_attn.out_proj quant. = 0.029158353805541992\n",
      "elapsed time - layer9 fc1 quant. = 0.10126113891601562\n",
      "elapsed time - layer9 fc2 quant. = 0.10361146926879883\n",
      "elapsed time - layer10 self_attn.k_proj quant. = 0.02974534034729004\n",
      "elapsed time - layer10 self_attn.v_proj quant. = 0.029536724090576172\n",
      "elapsed time - layer10 self_attn.q_proj quant. = 0.029605865478515625\n",
      "elapsed time - layer10 self_attn.out_proj quant. = 0.029610395431518555\n",
      "elapsed time - layer10 fc1 quant. = 0.10230374336242676\n",
      "elapsed time - layer10 fc2 quant. = 0.09917306900024414\n",
      "elapsed time - layer11 self_attn.k_proj quant. = 0.026311159133911133\n",
      "elapsed time - layer11 self_attn.v_proj quant. = 0.027222156524658203\n",
      "elapsed time - layer11 self_attn.q_proj quant. = 0.02627396583557129\n",
      "elapsed time - layer11 self_attn.out_proj quant. = 0.026677370071411133\n",
      "elapsed time - layer11 fc1 quant. = 0.10179448127746582\n",
      "elapsed time - layer11 fc2 quant. = 0.1004495620727539\n",
      "elapsed time - layer12 self_attn.k_proj quant. = 0.02661585807800293\n",
      "elapsed time - layer12 self_attn.v_proj quant. = 0.028416872024536133\n",
      "elapsed time - layer12 self_attn.q_proj quant. = 0.02748847007751465\n",
      "elapsed time - layer12 self_attn.out_proj quant. = 0.026311397552490234\n",
      "elapsed time - layer12 fc1 quant. = 0.10102391242980957\n",
      "elapsed time - layer12 fc2 quant. = 0.10104131698608398\n",
      "elapsed time - layer13 self_attn.k_proj quant. = 0.02730584144592285\n",
      "elapsed time - layer13 self_attn.v_proj quant. = 0.027060747146606445\n",
      "elapsed time - layer13 self_attn.q_proj quant. = 0.02731037139892578\n",
      "elapsed time - layer13 self_attn.out_proj quant. = 0.027057647705078125\n",
      "elapsed time - layer13 fc1 quant. = 0.09995770454406738\n",
      "elapsed time - layer13 fc2 quant. = 0.10187172889709473\n",
      "elapsed time - layer14 self_attn.k_proj quant. = 0.02524852752685547\n",
      "elapsed time - layer14 self_attn.v_proj quant. = 0.0264585018157959\n",
      "elapsed time - layer14 self_attn.q_proj quant. = 0.026727914810180664\n",
      "elapsed time - layer14 self_attn.out_proj quant. = 0.027622222900390625\n",
      "elapsed time - layer14 fc1 quant. = 0.09665846824645996\n",
      "elapsed time - layer14 fc2 quant. = 0.09852170944213867\n",
      "elapsed time - layer15 self_attn.k_proj quant. = 0.026309728622436523\n",
      "elapsed time - layer15 self_attn.v_proj quant. = 0.026697158813476562\n",
      "elapsed time - layer15 self_attn.q_proj quant. = 0.026594161987304688\n",
      "elapsed time - layer15 self_attn.out_proj quant. = 0.02765798568725586\n",
      "elapsed time - layer15 fc1 quant. = 0.10086250305175781\n",
      "elapsed time - layer15 fc2 quant. = 0.10204625129699707\n",
      "elapsed time - layer16 self_attn.k_proj quant. = 0.027446746826171875\n",
      "elapsed time - layer16 self_attn.v_proj quant. = 0.027523517608642578\n",
      "elapsed time - layer16 self_attn.q_proj quant. = 0.02649688720703125\n",
      "elapsed time - layer16 self_attn.out_proj quant. = 0.026965856552124023\n",
      "elapsed time - layer16 fc1 quant. = 0.09842991828918457\n",
      "elapsed time - layer16 fc2 quant. = 0.09915685653686523\n",
      "elapsed time - layer17 self_attn.k_proj quant. = 0.02678990364074707\n",
      "elapsed time - layer17 self_attn.v_proj quant. = 0.027051687240600586\n",
      "elapsed time - layer17 self_attn.q_proj quant. = 0.0269317626953125\n",
      "elapsed time - layer17 self_attn.out_proj quant. = 0.027031898498535156\n",
      "elapsed time - layer17 fc1 quant. = 0.09885668754577637\n",
      "elapsed time - layer17 fc2 quant. = 0.09833335876464844\n",
      "elapsed time - layer18 self_attn.k_proj quant. = 0.02545166015625\n",
      "elapsed time - layer18 self_attn.v_proj quant. = 0.029393911361694336\n",
      "elapsed time - layer18 self_attn.q_proj quant. = 0.029267072677612305\n",
      "elapsed time - layer18 self_attn.out_proj quant. = 0.02891850471496582\n",
      "elapsed time - layer18 fc1 quant. = 0.10413408279418945\n",
      "elapsed time - layer18 fc2 quant. = 0.11241340637207031\n",
      "elapsed time - layer19 self_attn.k_proj quant. = 0.030521631240844727\n",
      "elapsed time - layer19 self_attn.v_proj quant. = 0.03155207633972168\n",
      "elapsed time - layer19 self_attn.q_proj quant. = 0.0327298641204834\n",
      "elapsed time - layer19 self_attn.out_proj quant. = 0.03157329559326172\n",
      "elapsed time - layer19 fc1 quant. = 0.10964655876159668\n",
      "elapsed time - layer19 fc2 quant. = 0.1116492748260498\n",
      "elapsed time - layer20 self_attn.k_proj quant. = 0.030575990676879883\n",
      "elapsed time - layer20 self_attn.v_proj quant. = 0.03063058853149414\n",
      "elapsed time - layer20 self_attn.q_proj quant. = 0.03038930892944336\n",
      "elapsed time - layer20 self_attn.out_proj quant. = 0.029703855514526367\n",
      "elapsed time - layer20 fc1 quant. = 0.10160136222839355\n",
      "elapsed time - layer20 fc2 quant. = 0.10584473609924316\n",
      "elapsed time - layer21 self_attn.k_proj quant. = 0.03150177001953125\n",
      "elapsed time - layer21 self_attn.v_proj quant. = 0.029516220092773438\n",
      "elapsed time - layer21 self_attn.q_proj quant. = 0.03026437759399414\n",
      "elapsed time - layer21 self_attn.out_proj quant. = 0.029730558395385742\n",
      "elapsed time - layer21 fc1 quant. = 0.10341262817382812\n",
      "elapsed time - layer21 fc2 quant. = 0.10525679588317871\n",
      "elapsed time - layer22 self_attn.k_proj quant. = 0.02904677391052246\n",
      "elapsed time - layer22 self_attn.v_proj quant. = 0.029991865158081055\n",
      "elapsed time - layer22 self_attn.q_proj quant. = 0.030897140502929688\n",
      "elapsed time - layer22 self_attn.out_proj quant. = 0.03018951416015625\n",
      "elapsed time - layer22 fc1 quant. = 0.10338068008422852\n",
      "elapsed time - layer22 fc2 quant. = 0.1075906753540039\n",
      "elapsed time - layer23 self_attn.k_proj quant. = 0.029167652130126953\n",
      "elapsed time - layer23 self_attn.v_proj quant. = 0.02945566177368164\n",
      "elapsed time - layer23 self_attn.q_proj quant. = 0.0306394100189209\n",
      "elapsed time - layer23 self_attn.out_proj quant. = 0.029841899871826172\n",
      "elapsed time - layer23 fc1 quant. = 0.1049795150756836\n",
      "elapsed time - layer23 fc2 quant. = 0.10645866394042969\n",
      "elapsed time - layer24 self_attn.k_proj quant. = 0.028870344161987305\n",
      "elapsed time - layer24 self_attn.v_proj quant. = 0.029767513275146484\n",
      "elapsed time - layer24 self_attn.q_proj quant. = 0.030424833297729492\n",
      "elapsed time - layer24 self_attn.out_proj quant. = 0.03091287612915039\n",
      "elapsed time - layer24 fc1 quant. = 0.10396337509155273\n",
      "elapsed time - layer24 fc2 quant. = 0.10978579521179199\n",
      "elapsed time - layer25 self_attn.k_proj quant. = 0.02947854995727539\n",
      "elapsed time - layer25 self_attn.v_proj quant. = 0.0305328369140625\n",
      "elapsed time - layer25 self_attn.q_proj quant. = 0.031102657318115234\n",
      "elapsed time - layer25 self_attn.out_proj quant. = 0.030577421188354492\n",
      "elapsed time - layer25 fc1 quant. = 0.10688281059265137\n",
      "elapsed time - layer25 fc2 quant. = 0.11011409759521484\n",
      "elapsed time - layer26 self_attn.k_proj quant. = 0.0300447940826416\n",
      "elapsed time - layer26 self_attn.v_proj quant. = 0.030496597290039062\n",
      "elapsed time - layer26 self_attn.q_proj quant. = 0.031193971633911133\n",
      "elapsed time - layer26 self_attn.out_proj quant. = 0.031632423400878906\n",
      "elapsed time - layer26 fc1 quant. = 1.1112926006317139\n",
      "elapsed time - layer26 fc2 quant. = 0.13006854057312012\n",
      "elapsed time - layer27 self_attn.k_proj quant. = 0.030716896057128906\n",
      "elapsed time - layer27 self_attn.v_proj quant. = 0.030862092971801758\n",
      "elapsed time - layer27 self_attn.q_proj quant. = 0.030866622924804688\n",
      "elapsed time - layer27 self_attn.out_proj quant. = 0.03135180473327637\n",
      "elapsed time - layer27 fc1 quant. = 0.10618972778320312\n",
      "elapsed time - layer27 fc2 quant. = 0.10795807838439941\n",
      "elapsed time - layer28 self_attn.k_proj quant. = 0.02920818328857422\n",
      "elapsed time - layer28 self_attn.v_proj quant. = 0.030037641525268555\n",
      "elapsed time - layer28 self_attn.q_proj quant. = 0.031171083450317383\n",
      "elapsed time - layer28 self_attn.out_proj quant. = 0.03106212615966797\n",
      "elapsed time - layer28 fc1 quant. = 0.10635614395141602\n",
      "elapsed time - layer28 fc2 quant. = 0.1080634593963623\n",
      "elapsed time - layer29 self_attn.k_proj quant. = 0.029929161071777344\n",
      "elapsed time - layer29 self_attn.v_proj quant. = 0.031055688858032227\n",
      "elapsed time - layer29 self_attn.q_proj quant. = 0.03221893310546875\n",
      "elapsed time - layer29 self_attn.out_proj quant. = 0.03089308738708496\n",
      "elapsed time - layer29 fc1 quant. = 0.10623812675476074\n",
      "elapsed time - layer29 fc2 quant. = 0.10819268226623535\n",
      "elapsed time - layer30 self_attn.k_proj quant. = 0.030024051666259766\n",
      "elapsed time - layer30 self_attn.v_proj quant. = 0.030866384506225586\n",
      "elapsed time - layer30 self_attn.q_proj quant. = 0.031737327575683594\n",
      "elapsed time - layer30 self_attn.out_proj quant. = 0.030963659286499023\n",
      "elapsed time - layer30 fc1 quant. = 0.10375618934631348\n",
      "elapsed time - layer30 fc2 quant. = 0.10586953163146973\n",
      "elapsed time - layer31 self_attn.k_proj quant. = 0.028374910354614258\n",
      "elapsed time - layer31 self_attn.v_proj quant. = 0.03054499626159668\n",
      "elapsed time - layer31 self_attn.q_proj quant. = 0.030495405197143555\n",
      "elapsed time - layer31 self_attn.out_proj quant. = 0.02996516227722168\n",
      "elapsed time - layer31 fc1 quant. = 0.38983845710754395\n",
      "elapsed time - layer31 fc2 quant. = 0.10691237449645996\n"
     ]
    }
   ],
   "source": [
    "from spqr.quant_groups import Quantizer, quantize, dequantize, quantize_dequantize\n",
    "from spqr.spqr_engine import calculate_bit_error_injection_mask_quantized\n",
    "import time\n",
    "\n",
    "qweight_dict = {}\n",
    "row_perm_dict = {}\n",
    "scale_dict = {}\n",
    "zero_dict = {}\n",
    "for i in range(len(layers)):\n",
    "    qweight_dict[i] = {}\n",
    "    row_perm_dict[i] = {}\n",
    "    scale_dict[i] = {}\n",
    "    zero_dict[i] = {}\n",
    "    layer = layers[i]\n",
    "    sublayers = {name: sublayer for name, sublayer in layer.named_modules() if name in linear_list}\n",
    "    for name, sublayer in sublayers.items():\n",
    "        tick = time.time()\n",
    "        weight = sublayer.weight.detach().clone()\n",
    "        col_perm, dead, H_inv_diag = torch.load(f'collected_H/opt_6.7b_seed0_H_info/layers.{i}.{name}.pt')\n",
    "        weight = weight[:, col_perm]\n",
    "        weight[:, dead] = 0\n",
    "        weight = weight.to(device)\n",
    "        out_dim, in_dim = weight.shape\n",
    "\n",
    "        quantizer = Quantizer(weight.shape)\n",
    "        quantizer.configure(4, True, False)\n",
    "        quantizer.find_params(weight, weight=True)\n",
    "        row_perm = torch.argsort(quantizer.scale.T.squeeze(), descending=True).to(device)\n",
    "        qweight = quantize(weight, quantizer.scale, quantizer.zero, quantizer.maxq)\n",
    "        qweight = qweight[row_perm, :]\n",
    "        qweight_dict[i][name] = qweight.to(torch.int8)\n",
    "        row_perm_dict[i][name] = row_perm\n",
    "        scale_dict[i][name] = quantizer.scale\n",
    "        zero_dict[i][name] = quantizer.zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m row_perm \u001b[38;5;241m=\u001b[39m row_perm_dict[i][name]\n\u001b[1;32m      8\u001b[0m col_perm, _, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollected_H/opt_6.7b_seed0_H_info/layers.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m err_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_bit_error_injection_mask_quantized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape_as(qweight)\n\u001b[1;32m     12\u001b[0m err_mask_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(qweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m     13\u001b[0m err_mask_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(qweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m~/workspace/spqr_sens/lib/spqr/spqr_engine.py:41\u001b[0m, in \u001b[0;36mcalculate_bit_error_injection_mask_quantized\u001b[0;34m(X, ber, seed, bitwidth, percentile)\u001b[0m\n\u001b[1;32m     38\u001b[0m eligible_bit_indices \u001b[38;5;241m=\u001b[39m eligible_indices\u001b[38;5;241m.\u001b[39mrepeat_interleave(bitwidth) \u001b[38;5;241m*\u001b[39m bitwidth \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(bitwidth)\u001b[38;5;241m.\u001b[39mrepeat(eligible_indices\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mto(eligible_indices\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 무작위로 target_error_bits 개수만큼 선택\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m selected_bit_indices \u001b[38;5;241m=\u001b[39m eligible_bit_indices[\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43meligible_bit_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m[:target_error_bits]]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 최종 오류 마스크 생성\u001b[39;00m\n\u001b[1;32m     44\u001b[0m final_error_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m*\u001b[39m bitwidth, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "for i in range(len(layers)):\n",
    "    layer = layers[i]\n",
    "    sublayers = {name: sublayer for name, sublayer in layer.named_modules() if name in linear_list}\n",
    "    for name, sublayer in sublayers.items():\n",
    "        qweight = qweight_dict[i][name]\n",
    "        row_perm = row_perm_dict[i][name]\n",
    "        col_perm, _, _ = torch.load(f'collected_H/opt_6.7b_seed0_H_info/layers.{i}.{name}.pt')\n",
    "        err_matrix = calculate_bit_error_injection_mask_quantized(\n",
    "            qweight, 1e-3, seed, 4, 100\n",
    "        ).reshape_as(qweight)\n",
    "        err_mask_row = round(qweight.shape[0] * (1/100))\n",
    "        err_mask_col = round(qweight.shape[1] * (1/100))\n",
    "        err_matrix[:err_mask_row, :err_mask_col] = 0\n",
    "        qweight = qweight.to(torch.int32) ^ err_matrix.to(device)\n",
    "        row_invperm = torch.argsort(row_perm)\n",
    "        qweight = qweight[row_invperm, :]\n",
    "        scale = scale_dict[i][name]\n",
    "        zero = zero_dict[i][name]\n",
    "        dqweight = dequantize(qweight, scale, zero)\n",
    "\n",
    "        col_invperm = torch.argsort(col_perm)\n",
    "        dqweight = dqweight[:, col_invperm]\n",
    "        sublayer.weight.data = dqweight.to(device)\n",
    "        seed = seed + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Perplexity 7077.686: 100%|██████████| 140/140 [00:32<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7077.685546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if model.device == device:\n",
    "    print(evaluate_perplexity(model, tokenizer))\n",
    "else:\n",
    "    print(evaluate_perplexity(model.to(device), tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spqr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
