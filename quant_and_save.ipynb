{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwjeong/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "H_dict = torch.load('collected_H/H_opt-6.7b_pajama_seed0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.85s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from spqr.evalutils import evaluate_perplexity\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "model_path = '/raid/LLM/opt-6.7b/'\n",
    "device = 'cuda:3'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.half)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spqr.quant_groups import Quantizer, quantize, dequantize, quantize_dequantize\n",
    "from spqr.spqr_engine import calculate_bit_error_injection_mask_quantized\n",
    "import time\n",
    "\n",
    "linear_list = [\n",
    "    'self_attn.k_proj',\n",
    "    'self_attn.q_proj',\n",
    "    'self_attn.v_proj',\n",
    "    'self_attn.out_proj',\n",
    "    'fc1',\n",
    "    'fc2',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "qweight_dict = {}\n",
    "row_perm_dict = {}\n",
    "scale_dict = {}\n",
    "zero_dict = {}\n",
    "for i in range(len(layers)):\n",
    "    qweight_dict[i] = {}\n",
    "    row_perm_dict[i] = {}\n",
    "    scale_dict[i] = {}\n",
    "    zero_dict[i] = {}\n",
    "    layer = layers[i]\n",
    "    sublayers = {name: sublayer for name, sublayer in layer.named_modules() if name in linear_list}\n",
    "    for name, sublayer in sublayers.items():\n",
    "        tick = time.time()\n",
    "        weight = sublayer.weight.detach().clone()\n",
    "        col_perm, dead, H_inv_diag = H_dict[i][name]\n",
    "        weight = weight[:, col_perm]\n",
    "        weight[:, dead] = 0\n",
    "        weight = weight.to(device)\n",
    "        out_dim, in_dim = weight.shape\n",
    "\n",
    "        quantizer = Quantizer(weight.shape)\n",
    "        quantizer.configure(4, True, False)\n",
    "        quantizer.find_params(weight, weight=True)\n",
    "        row_perm = torch.argsort(quantizer.scale.T.squeeze(), descending=True).to(device)\n",
    "        qweight = quantize(weight, quantizer.scale, quantizer.zero, quantizer.maxq)\n",
    "        qweight = qweight[row_perm, :]\n",
    "        qweight_dict[i][name] = qweight.to(torch.int8)\n",
    "        row_perm_dict[i][name] = row_perm\n",
    "        scale_dict[i][name] = quantizer.scale\n",
    "        zero_dict[i][name] = quantizer.zero\n",
    "    \n",
    "torch.save(qweight_dict, f'ordered_quant_models/opt-6.7b-qweight.pt')\n",
    "torch.save(row_perm_dict, f'ordered_quant_models/opt-6.7b-row-perm.pt')\n",
    "torch.save(scale_dict, f'ordered_quant_models/opt-6.7b-scale.pt')\n",
    "torch.save(zero_dict, f'ordered_quant_models/opt-6.7b-zero.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spqr.errorutils import error_injection\n",
    "\n",
    "qweight_dict = torch.load(f'ordered_quant_models/opt-6.7b-qweight.pt')\n",
    "row_perm_dict = torch.load(f'ordered_quant_models/opt-6.7b-row-perm.pt')\n",
    "scale_dict = torch.load(f'ordered_quant_models/opt-6.7b-scale.pt')\n",
    "zero_dict = torch.load(f'ordered_quant_models/opt-6.7b-zero.pt')\n",
    "for i in qweight_dict:\n",
    "    for name in qweight_dict[i]:\n",
    "        qweight_dict[i][name] = qweight_dict[i][name].to(device)\n",
    "        row_perm_dict[i][name] = row_perm_dict[i][name].to(device)\n",
    "        scale_dict[i][name] = scale_dict[i][name].to(device)\n",
    "        zero_dict[i][name] = zero_dict[i][name].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error masking percentile: 10%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m col_perm, _, _ \u001b[38;5;241m=\u001b[39m H_dict[i][name]\n\u001b[1;32m     13\u001b[0m col_perm \u001b[38;5;241m=\u001b[39m col_perm\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m err_matrix \u001b[38;5;241m=\u001b[39m \u001b[43merror_injection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape_as(qweight)\n\u001b[1;32m     17\u001b[0m err_mask_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(qweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m (percentile\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m     18\u001b[0m err_mask_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(qweight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m (percentile\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m~/workspace/spqr/lib/spqr/errorutils.py:22\u001b[0m, in \u001b[0;36merror_injection\u001b[0;34m(param, rate, seed, wbits, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_injection\u001b[39m(param, rate, seed, wbits, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     err_mat \u001b[38;5;241m=\u001b[39m \u001b[43merror_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwbits\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     23\u001b[0m     int_form \u001b[38;5;241m=\u001b[39m err_mat\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39melement_size() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/spqr/lib/spqr/errorutils.py:17\u001b[0m, in \u001b[0;36merror_gen\u001b[0;34m(param, rate, seed, wbits)\u001b[0m\n\u001b[1;32m     14\u001b[0m bitwidth \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39melement_size()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     16\u001b[0m bin_error \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sp\u001b[38;5;241m.\u001b[39mrandom(np\u001b[38;5;241m.\u001b[39mprod(orig_size), wbits, density\u001b[38;5;241m=\u001b[39mrate, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed))\u001b[38;5;241m.\u001b[39mtoarray())\n\u001b[0;32m---> 17\u001b[0m error_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconv_bin2int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwbits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m bin_error\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_matrix\u001b[38;5;241m.\u001b[39mview(orig_size)\n",
      "File \u001b[0;32m~/workspace/spqr/lib/spqr/errorutils.py:9\u001b[0m, in \u001b[0;36mconv_bin2int\u001b[0;34m(bin, wbits)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mbin\u001b[39m)):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbin\u001b[39m[i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m((wbits\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39mi)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for percentile in range(10, 1, -1):\n",
    "    print(f'error masking percentile: {percentile}%')\n",
    "    seed = 0\n",
    "    cp_model = deepcopy(model).to(device)\n",
    "    layers = cp_model.model.decoder.layers\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        sublayers = {name: sublayer for name, sublayer in layer.named_modules() if name in linear_list}\n",
    "        for name, sublayer in sublayers.items():\n",
    "            qweight = qweight_dict[i][name].clone()\n",
    "            row_perm = row_perm_dict[i][name]\n",
    "            col_perm, _, _ = H_dict[i][name]\n",
    "            col_perm = col_perm.to(device)\n",
    "            err_matrix = error_injection(\n",
    "                qweight, 1e-3, seed, 4, device\n",
    "            ).reshape_as(qweight)\n",
    "            err_mask_row = round(qweight.shape[0] * (percentile/100))\n",
    "            err_mask_col = round(qweight.shape[1] * (percentile/100))\n",
    "            err_matrix[:err_mask_row, :err_mask_col] = 0\n",
    "            qweight = qweight.to(torch.int32) ^ err_matrix.to(device)\n",
    "            row_invperm = torch.argsort(row_perm).to(device)\n",
    "            qweight = qweight[row_invperm, :]\n",
    "            scale = scale_dict[i][name].to(device)\n",
    "            zero = zero_dict[i][name].to(device)\n",
    "            dqweight = dequantize(qweight, scale, zero)\n",
    "\n",
    "            col_invperm = torch.argsort(col_perm).to(device)\n",
    "            dqweight = dqweight[:, col_invperm]\n",
    "            sublayer.weight.data = dqweight.to(device)\n",
    "            seed = seed + 10\n",
    "\n",
    "    if model.device == device:\n",
    "        print(evaluate_perplexity(cp_model, tokenizer))\n",
    "    else:\n",
    "        print(evaluate_perplexity(cp_model.to(device), tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spqr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
